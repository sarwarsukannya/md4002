---
title: "MD"
format: html
editor: visual
---

```{r setup, include=FALSE}
# Set the working directory for all chunks
knitr::opts_knit$set(root.dir = "/home/workspace/files/MD0004")
```

# Results

## Demographics

```{r}
library(arsenal)

visLvl <- c("bl", "m12", "m24", "m36", "m48", "m60", "m72", "m84", "m96", "m108", "m120")
ad_data <- read.csv( "data/subset/ADNIMERGE_03Feb2025.csv" )
  ad_data <- subset( ad_data, VISCODE %in% visLvl )
  ad_data$VISCODE <- factor( ad_data$VISCODE, levels = visLvl )
  ad_data$APOE4 <- factor( ad_data$APOE4, levels = c(0,1,2) )
  numVar <- colnames(ad_data)[c(9,11, 20:27)]
  catVar <- colnames(ad_data)[c(61, 10, 12, 13, 15)]
  ad_data[numVar] <- lapply(ad_data[numVar], as.numeric)
    sF = as.formula( paste( "VISCODE", paste( c(catVar, numVar), collapse="+"), sep="~" ) )
tab1 <- arsenal::tableby( sF, data=ad_data, numeric.stats = "meansd" )
summary( tab1 )
```

## Helper Functions

```{r}
# helper functions
# univariate outlier detection and capping
f_cap_outlier_iqr <- function(x, vars) {
  Q1 <- quantile(x[[vars]], 0.25, na.rm = TRUE)
  Q3 <- quantile(x[[vars]], 0.75, na.rm = TRUE)
  IQR_val <- IQR(x[[vars]], na.rm = TRUE)
  lower_bound <- Q1 - 1.5 * IQR_val
  upper_bound <- Q3 + 1.5 * IQR_val
  x[[vars]] <- ifelse(x[[vars]] < lower_bound, lower_bound, 
                      ifelse(x[[vars]] > upper_bound, upper_bound, x[[vars]]))
  return(x)
}

# Youden index, critical point, and ROC plot
calculate_youden_index <- function(data, binary_var, continuous_var) {
  library(pROC)
  library(ggplot2)
  
  roc_curve <- roc(data[[binary_var]], data[[continuous_var]])
  youden_index <- which.max(roc_curve$sensitivities + roc_curve$specificities - 1)
  critical_point <- roc_curve$thresholds[youden_index]
  auc_value <- auc(roc_curve)
  ci_auc <- ci.auc(roc_curve)
  
 ci_obj <- ci.se(roc_curve, specificities = seq(0, 1, 0.01), boot.n = 1000)

 ci_df <- data.frame(
  specificity = as.numeric(rownames(ci_obj)),
  ci_lower = ci_obj[,1],
  sensitivity = ci_obj[,2],
  ci_upper = ci_obj[,3]
)

# Plot with ggplot2
roc_plot <- ggplot(ci_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "blue") +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = "blue", alpha = 0.2) +
  labs(
    x = "1 - Specificity (False Positive Rate)",
    y = "Sensitivity (True Positive Rate)"
  ) +
  ggtitle(paste("ROC Curve (AUC =", signif(auc_value, 2), ")")) +
  theme_minimal()
  
  print(roc_plot)
  
  return(list(critical_point = critical_point, auc = auc_value, ci = ci_df))
}

# Time categories to numeric
convert_time_to_survival <- function(viscode) {
  time_map <- c("bl" = 0, "m12" = 12, "m24" = 24, "m36" = 36, "m48" = 48, 
                "m60" = 60, "m72" = 72, "m84" = 84, "m96" = 96, 
                "m108" = 108, "m120" = 120)
  time <- time_map[viscode]
  return(as.numeric(time))
}
```

## HOMA-IR

```{r}
# This will be used to calculate HOMA-IR that requires both insulin and glucose levels
# Use baseline (bl) and remove entries with QC flags for LDD and LOW
# insulin RAW
ins_raw <- read.csv( "data/subset/adni_plasma_raw_multiplex_11Nov2010.csv" )
  #ins_raw$analyte[grep("insulin", ins_raw$analyte, ignore.case=T)]
  # Insulin (uIU/mL)
  ins_qc <- subset( ins_raw, analyte %in% "Insulin (uIU/mL)" )
  ins_qc <- subset( ins_qc, belowLDD == 0 & readLOW == 0 & Visit_Code == "bl" )
  ins_qc_out <- data.frame( RID = ins_qc$RID, visit = ins_qc$Visit_Code, insulin = ins_qc$avalue )
```

```{r}
# This will be used to calculate HOMA-IR that requires both insulin and glucose levels
# Use baseline (bl)
# glucose (NG uses mmol/l)
# mg/dL = 18.018∗mmol/l
extract_glucose <- function(file_path) {
ng <- read.csv( file_path )
  colsK <- colnames(ng)[grep("GLC|TAG", colnames(ng), ignore.case=T)]
  # glucose (GLC)
  glu <- ng[, c("RID", "VISCODE", "VISCODE2", colsK)]
  glu$QC <- apply(ng[, grep("TAG", colnames(ng))], 1, sum)
    glu <- subset( glu, QC == 0 & VISCODE2 == "bl" )
    glu_out <- data.frame( RID = glu$RID, visit = glu$VISCODE2, glucose = glu$GLC )
    glu_out <- glu_out[!is.na(glu_out$glucose), ]
    #glu_out <- subset( glu_out, RID %in% unique(glu_out$RID) )
    glu_out <- glu_out[!duplicated(glu_out$RID), ]
    return(glu_out)
}

glu_out = extract_glucose("data/subset/ADNINIGHTINGALE_20210219_12Feb2025.csv")
```

```{r}
# This will be used to calculate HOMA-IR that requires both insulin and glucose levels
# merge insulin and glucose
# https://thebloodcode.com/calculators/
homa = merge( ins_qc_out, glu_out, by=c("RID", "visit") )
  homa$insulin <- as.numeric(homa$insulin)
  homa$glucose <- homa$glucose * 18.018
  
  # outlier capping
  homa <- f_cap_outlier_iqr(homa, vars = "insulin")
  homa <- f_cap_outlier_iqr(homa, vars = "glucose")
  
  homa$homa_ir <- (homa$insulin * homa$glucose) / 22.5
  head(homa)
  hist(homa$homa_ir)
  hist(log10(homa$homa_ir))
```

### METS-IR

```{r}
# This will be used to calculate METS-IR
# Use baseline (bl)
# triglycerides (NG uses mmol/l)
# mg/dL = 18.018∗mmol/l

extract_triglycerides <- function(file_path) {
  ng <- read.csv(file_path)
  colsK <- colnames(ng)[grep("SERUM.TG|TAG", colnames(ng), ignore.case=TRUE)]
  tg <- ng[, c("RID", "VISCODE", "VISCODE2", colsK)]
  tg$QC <- apply(tg[, grep("TAG", colnames(tg))], 1, sum)
  tg <- subset(tg, QC == 0 & VISCODE2 == "bl")
  tg_out <- data.frame(RID = tg$RID, visit = tg$VISCODE2, triglycerides = tg$SERUM.TG)
  tg_out <- tg_out[!is.na(tg_out$triglycerides), ]
  tg_out <- tg_out[!duplicated(tg_out$RID), ]
  # outlier capping
  tg_out <- f_cap_outlier_iqr(tg_out, vars = "triglycerides")
  return(tg_out)
}

tg_out = extract_triglycerides("data/subset/ADNINIGHTINGALE_20210219_12Feb2025.csv")

# HDL-c (NG uses mmol/l)
# HDL.C
extract_hdl <- function(file_path) {
  ng <- read.csv(file_path)
  colsK <- colnames(ng)[grep("HDL.C|TAG", colnames(ng), ignore.case=T)]
  tg <- ng[, c("RID", "VISCODE", "VISCODE2", colsK)]
  tg$QC <- apply(tg[, grep("TAG", colnames(tg))], 1, sum)
    tg <- subset( tg, QC == 0 & VISCODE2 == "bl" )
    tg_out <- data.frame( RID = tg$RID, visit = tg$VISCODE2, hdl = tg$HDL.C )
    tg_out <- tg_out[!is.na(tg_out$hdl), ]
    tg_out <- tg_out[!duplicated(tg_out$RID), ]
    # outlier capping
    tg_out <- f_cap_outlier_iqr(tg_out, vars = "hdl")
    return(tg_out)
}

hdl_out = extract_hdl("data/subset/ADNINIGHTINGALE_20210219_12Feb2025.csv")
```

### BMI

```{r}
vitals <- read.csv( "data/subset/VITALS_03Feb2025.csv" )
calculate_bmi_data <- function(vitals) {
  # Identify relevant columns
  colsK <- colnames(vitals)[grep("VSWEIGHT|VSWTUNIT|VSHEIGHT|VSHTUNIT", colnames(vitals), ignore.case = TRUE)]
  
  bmi <- vitals[, c("RID", "VISCODE", "VISCODE2", colsK)]
  bmi <- subset(bmi, VISCODE2 == "sc")
  bmi$VSHEIGHT <- ifelse(bmi$VSHEIGHT < 0, NA, bmi$VSHEIGHT)
  bmi$VSWEIGHT <- ifelse(bmi$VSWEIGHT < 0, NA, bmi$VSWEIGHT)
  bmi <- bmi[!is.na(bmi$VSHEIGHT) & !is.na(bmi$VSWEIGHT), ]
  
  valid_height_units <- bmi$VSHTUNIT %in% c(1, 2)
  valid_weight_units <- bmi$VSWTUNIT %in% c(1, 2)
  
  bmi <- bmi[valid_height_units & valid_weight_units, ]

  bmi <- bmi[!(bmi$VSHTUNIT == 1 & (bmi$VSHEIGHT < 55 | bmi$VSHEIGHT > 85)), ]  # Inches range
  bmi <- bmi[!(bmi$VSHTUNIT == 2 & (bmi$VSHEIGHT < 140 | bmi$VSHEIGHT > 216)), ]  # Centimeters range

  bmi <- bmi[!(bmi$VSWTUNIT == 1 & (bmi$VSWEIGHT < 80 | bmi$VSWEIGHT > 500)), ]  # Pounds range
  bmi <- bmi[!(bmi$VSWTUNIT == 2 & (bmi$VSWEIGHT < 36 | bmi$VSWEIGHT > 227)), ]   # Kilograms range
  
  bmi$WEIGHT <- ifelse(bmi$VSWTUNIT == 1, bmi$VSWEIGHT / 2.205, bmi$VSWEIGHT)
  bmi$HEIGHT <- ifelse(bmi$VSHTUNIT == 1, bmi$VSHEIGHT * 2.54, bmi$VSHEIGHT)

  bmi$bmi <- bmi$WEIGHT / (bmi$HEIGHT/100)^2
  bmi <- bmi[!duplicated(bmi$RID), ]
  
  return(bmi)
}

bmi = calculate_bmi_data(vitals)
```

```{r}

df_list <- list( glu_out, tg_out, hdl_out, bmi )
mets = Reduce(function(x, y) merge(x, y, by = "RID", all = FALSE), df_list)

calculate_METS_IR <- function(Glucose, Triglycerides, BMI, HDL_C) {
  METS_IR <- (log((2 * (Glucose*18.018)) + (Triglycerides*18.018)) * BMI) / log(HDL_C*18.018)
  return(METS_IR)
}

mets$mets = calculate_METS_IR(mets$glucose, mets$triglycerides, mets$bmi, mets$hdl)

idx <- intersect( homa$RID, mets$RID )
  a <- subset( homa, RID %in% idx )
  b <- subset( mets, RID %in% idx )
  ab <- merge( a, b, by="RID" )

cor( ab$homa_ir, ab$mets, method="spearman" )
```

### DM for a subset - ROC

```{r}
library(pROC)
diab <- read.csv( "data/subset/ADSP_PHC_VRF_Dec2023.csv" )
  diab <- subset( diab, VISCODE2 %in% c("sc", "scmri", "bl"))
   #length(intersect(ab$RID, diab$RID)) # 306
  diab <- subset( diab, RID %in% intersect(ab$RID, diab$RID) )
diab <- data.frame( RID = diab$RID, diabetes = diab$PHC_Diabetes )
  
ab <- merge( ab, diab, by="RID")

critical_point_homa <- calculate_youden_index(ab, "diabetes", "homa_ir")
critical_point_mets <- calculate_youden_index(ab, "diabetes", "mets")

print(critical_point_homa[[2]])
print(critical_point_mets[[2]])

# Using METS scoring as proxy for insulin resistance since AUC[mets] > AUC[homa_ir]
```
### ROC curve and Youden’s Index
```{r}
library(pROC)
# ROC curve and Youden’s Index (J=sensitivity+specificity−1)
roc_curve <- roc(ab[["diabetes"]], ab[["mets"]])
j <- coords(roc_curve, x="best", best.method="youden")
par(pty = "s") # Make this ROC plot square
plot(roc_curve, print.thres = "best", print.thres.best.method = "youden")
# METS-IR Value FROM https://www.mdcalc.com/calc/10181/metabolic-score-insulin-resistance-mets-ir#evidence
# Risk of Developing T2D
# ≤50.39 --> Low
# >50.39 --> High

sum(ab[["mets"]]<=j$threshold)
sum(ab[["mets"]]>j$threshold)

sum(ab[["mets"]]<=50.39)
sum(ab[["mets"]]>50.39)

# Calculate counts
group_counts <- c(
  sum(ab[["mets"]] <= j$threshold),
  sum(ab[["mets"]] > j$threshold),
  sum(ab[["mets"]] <= 50.39),
  sum(ab[["mets"]] > 50.39)
)

# Labels for x-axis
group_labels <- c(
  paste0("<= ", round(j$threshold,2), "\n Low" ),
  paste0("> ", round(j$threshold,2), "\n High" ),
  "<= 50.39 \n Low",
  "> 50.39 \n High"
)

# Group type: first two are "Data", next two are "Reference"
group_types <- c("Data", "Data", "Reference", "Reference")

# Assign colors based on group type
colors <- ifelse(group_types == "Data", "steelblue", "darkorange")

# Plot and save bar positions
bar_positions <- barplot(group_counts,
                         names.arg = group_labels,
                         main = "",
                         ylab = "Count",
                         col = colors)

text(x = bar_positions,
     y = group_counts - 15,
     labels = group_counts,
     pos = 3,
     cex = 0.9,
     font = 2)

# Add legend
legend("topright",
       legend = c("Data", "Reference"),
       fill = c("steelblue", "darkorange"))

```

### METS Categories - Quantiles

```{r}
# Categorize 'mets' into 3 categories as a proxy for insulin resistance
categorize_mets <- function(mets_values) {
  quantiles <- quantile(mets_values, probs = c(0.33, 0.66), na.rm = TRUE)
  categories <- cut(mets_values, 
                    breaks = c(-Inf, quantiles[1], quantiles[2], Inf), 
                    labels = c("Low", "Medium", "High"), 
                    include.lowest = TRUE)
  return(categories)
}

ab$mets_category <- categorize_mets(ab$mets)
mets$mets_category <- categorize_mets(mets$mets)
table(mets$mets_category)
```

### METS Categories - optimal cut-off (Data)

```{r}
categorize_mets_cutoff <- function(mets_values) {
  categories <- cut(mets_values, 
                    breaks = c(-Inf, j$threshold, Inf), 
                    labels = c("Low", "High"), 
                    include.lowest = TRUE)
  return(categories)
}

mets$mets_category_cutoff <- categorize_mets_cutoff(mets$mets)
table(mets$mets_category_cutoff)
```

### METS Categories - reference

```{r}
ref = 50.39 
categorize_mets_ref <- function(mets_values) {
  categories <- cut(mets_values, 
                    breaks = c(-Inf, ref, Inf), 
                    labels = c("Low", "High"), 
                    include.lowest = TRUE)
  return(categories)
}

mets$mets_category_ref <- categorize_mets_ref(mets$mets)
table(mets$mets_category_ref)
```

### Time-to-event

```{r}
library(survival)
library(survminer)
library(ggplot2)
library(dplyr)
library(ggfortify)
```

```{r}
# exclude subjects with baseline Alzheimer's (AD), EMCI, LMCI & missing diagnosis label
ad_mets <- merge( ad_data, mets[, c("RID", "mets", "mets_category_ref", "mets_category_cutoff", "mets_category")], by="RID" )
ad_mets <- subset( ad_mets, !DX_bl %in% c("AD", "EMCI", "LMCI") )
ad_mets <- ad_mets[!nchar(ad_mets$DX)<2,]
table(ad_mets$DX)
```

```{r}

ad_mets$time <- convert_time_to_survival(ad_mets$VISCODE)
ad_mets$status <- ifelse(ad_mets$DX == "Dementia", 1, 0)
#km <- with( ad_mets, Surv(time, status) )
#head(km,80)
```

### Alluvial Plot

```{r}
library(dplyr)
library(ggplot2)
library(ggalluvial)

plot <- ggplot( ad_mets, aes(x = VISCODE, stratum = DX, alluvium = RID, fill = DX)) +
  geom_flow(stat = "alluvium", aes.bind = FALSE, alpha = 0.7) +
  geom_stratum() +
  #scale_x_discrete(limits = ad_mets$time, expand = c(0, 0)) +
  scale_fill_manual(values = c("CN" = "skyblue", "MCI" = "orange", "Dementia" = "red")) +
  labs(title = "Diagnosis (DX) Transitions Over Visits",
       x = "Visit",
       y = "Count",
       fill = "Diagnosis") +
  theme_minimal()
plot
```

```{r}
km_fit <- survfit(Surv(time, status) ~ 1, data=ad_mets)
km_summary <- summary( km_fit, times = seq(0, 120, by=12) )
cols <- lapply(c(2:4,6,14,15) , function(x) km_summary[x])
tbl <- do.call(data.frame, cols)
  tbl$surv <- signif(tbl$surv, 3)
  tbl$lower <- signif(tbl$lowe, 3)
  tbl$upper <- signif(tbl$upper, 3)
head(tbl)
write.csv(tbl, "results/survfit_tbl_ad_mets.csv")
```

```{r}
km_trt_fit_cutoff <- survfit( Surv(time, status) ~ mets_category_cutoff, data=ad_mets )
autoplot(km_trt_fit_cutoff, conf.int = FALSE) + theme_bw() + 
  ylab("transition prob. CN-->AD/Dementia") + 
  xlab("time (months)") +
  ggtitle("METS-IR: DATA")
```

```{r}
# Customized survival curves
survminer::ggsurvplot(km_trt_fit_cutoff, data = ad_mets,
 surv.median.line = "hv",
 pval = TRUE,
 conf.int = FALSE,
 # Add risk table
 risk.table = TRUE,
 tables.height = 0.2,
 tables.theme = theme_cleantable(),
 ggtheme = theme_bw()
)
```

```{r}
cox_fit_cutoff <- coxph( Surv(time, status) ~  mets_category_cutoff + log10(AGE) + PTGENDER + log10(PTEDUCAT), data = ad_mets )
summary(cox_fit_cutoff)
```

### Summary COX table

```{r}
library(gtsummary)
    cox_fit_cutoff %>%
      tbl_regression(
        exponentiate = TRUE,
        intercept = FALSE,
        conf.int = TRUE,
        digits = 2
      ) %>% add_vif() %>% add_glance_table(include = c("concordance", "AIC"))
```

```{r}
# Check proportional hazards assumption
cox_zph_cutoff <- cox.zph(cox_fit_cutoff)
print(cox_zph)

# Plot Schoenfeld residuals
plot(cox_zph_cutoff)

# Check for influential observations
ggcoxdiagnostics(cox_fit_cutoff, type = "dfbeta", linear.predictions = FALSE, ggtheme = theme_minimal())
```

### Survival - Reference
```{r}
km_trt_fit_ref <- survfit( Surv(time, status) ~ mets_category_ref, data=ad_mets )
autoplot(km_trt_fit_ref, conf.int = FALSE) + theme_bw() + 
  ylab("transition prob. CN-->AD/Dementia") + 
  xlab("time (months)") +
  ggtitle("METS-IR: Reference")
```

```{r}
# Customized survival curves
survminer::ggsurvplot(km_trt_fit_ref, data = ad_mets,
 surv.median.line = "hv",
 pval = TRUE,
 conf.int = FALSE,
 # Add risk table
 risk.table = TRUE,
 tables.height = 0.2,
 tables.theme = theme_cleantable(),
 ggtheme = theme_bw()
)
```

```{r}
cox_fit_ref <- coxph( Surv(time, status) ~  mets_category_ref + log10(AGE) + PTGENDER + log10(PTEDUCAT), data = ad_mets )
summary(cox_fit_ref)
```

### Summary COX table

```{r}
library(gtsummary)
    cox_fit_ref %>%
      tbl_regression(
        exponentiate = TRUE,
        intercept = FALSE,
        conf.int = TRUE,
        digits = 2
      ) %>% add_vif() %>% add_glance_table(include = c("concordance", "AIC"))
```

```{r}
# Check proportional hazards assumption
cox_zph_ref <- cox.zph(cox_fit_ref)
print(cox_zph_ref)

# Plot Schoenfeld residuals
plot(cox_zph_ref)

# Check for influential observations
ggcoxdiagnostics(cox_fit_ref, type = "dfbeta", linear.predictions = FALSE, ggtheme = theme_minimal())
```

### Linear Mixed Models - pTAU181

```{r}
library(lme4)
library(afex)
library(emmeans)
library(ggeffects)

# plasma P-tau181
pTau <- read.csv( "data/subset/UGOTPTAU181_06_18_20_03Feb2025.csv" )
  pTau <- subset( pTau, VISCODE2 %in% visLvl )
  # length(intersect(ad_mets$RID, pTau$RID)) 400
  ad_mets_ptau <- merge( ad_mets, pTau[, c("RID", "VISCODE", "PLASMAPTAU181")], by=c("RID", "VISCODE") )
  ad_mets_ptau <- f_cap_outlier_iqr(ad_mets_ptau, vars = "PLASMAPTAU181")
  hist(ad_mets_ptau$PLASMAPTAU181)
  
ad_mets_ptau$RID <- as.factor( ad_mets_ptau$RID )
ad_mets_ptau$mets_category_cutoff <- as.factor( ad_mets_ptau$mets_category_cutoff )
ad_mets_ptau$PTGENDER <- as.factor(ad_mets_ptau$PTGENDER)

lmm_fit <- lmer( log10(PLASMAPTAU181) ~ mets_category_cutoff * time + AGE + PTGENDER + (1 | SITE/RID), data = ad_mets_ptau )
#ggpredict(lmm_fit, c("time", "mets_category_ref"), back_transform = TRUE, ci_level = NA, interval = "confidence", show_data = TRUE) %>% #plot(show_data = TRUE)
ggpredict(lmm_fit, c("time", "mets_category_cutoff"), back_transform = TRUE, ci_level = 0.95, interval = "confidence", show_data = TRUE) %>% plot()

# Summary of the model
summary(lmm_fit)
# Check model diagnostics
plot(lmm_fit)
```

```{r}
library(sjPlot)
tab_model(lmm_fit)
```

### Linear Mixed Models - Abeta

```{r}
library(lme4)
library(afex)
library(emmeans)
library(ggeffects)

# Abeta
ad_mets_abeta <- subset( ad_mets, VISCODE %in% visLvl )
  ad_mets_abeta <- ad_mets_abeta[!is.na(ad_mets_abeta$ABETA), ]
  ad_mets_abeta <- f_cap_outlier_iqr(ad_mets_abeta, vars = "ABETA")
  hist(log10(ad_mets_abeta$ABETA))
  
ad_mets_abeta$RID <- as.factor( ad_mets_abeta$RID )
ad_mets_abeta$mets_category_cutoff <- as.factor( ad_mets_abeta$mets_category_cutoff )
ad_mets_abeta$PTGENDER <- as.factor(ad_mets_abeta$PTGENDER)

lmm_fit_abeta <- lmer( log10(ABETA) ~ mets_category_cutoff * time + AGE + PTGENDER + (1 | SITE/RID), data = ad_mets_abeta )
#ggpredict(lmm_fit, c("time", "mets_category_ref"), back_transform = TRUE, ci_level = NA, interval = "confidence", show_data = TRUE) %>% #plot(show_data = TRUE)
ggpredict(lmm_fit_abeta, c("time", "mets_category_cutoff"), back_transform = TRUE, ci_level = 0.95, interval = "confidence", show_data = TRUE) %>% plot()

# Summary of the model
summary(lmm_fit_abeta)
# Check model diagnostics
plot(lmm_fit_abeta)
```

```{r}
library(sjPlot)
tab_model(lmm_fit_abeta)
```

### Linear Mixed Models - TAU

```{r}
library(lme4)
library(afex)
library(emmeans)
library(ggeffects)

# TAU
ad_mets_tau <- subset( ad_mets, VISCODE %in% visLvl )
  ad_mets_tau <- ad_mets_tau[!is.na(ad_mets_tau$TAU), ]
  ad_mets_tau <- f_cap_outlier_iqr(ad_mets_tau, vars = "TAU")
  hist(log10(ad_mets_tau$TAU))
  
ad_mets_tau$RID <- as.factor( ad_mets_tau$RID )
ad_mets_tau$mets_category_cutoff <- as.factor( ad_mets_tau$mets_category_cutoff )
ad_mets_tau$PTGENDER <- as.factor(ad_mets_tau$PTGENDER)

lmm_fit_tau <- lmer( log10(TAU) ~ mets_category_cutoff * time + AGE + PTGENDER + (1 | SITE/RID), data = ad_mets_tau )
#ggpredict(lmm_fit, c("time", "mets_category_ref"), back_transform = TRUE, ci_level = NA, interval = "confidence", show_data = TRUE) %>% #plot(show_data = TRUE)
ggpredict(lmm_fit_tau, c("time", "mets_category_cutoff"), back_transform = TRUE, ci_level = 0.95, interval = "confidence", show_data = TRUE) %>% plot()

# Summary of the model
summary(lmm_fit_tau)
# Check model diagnostics
plot(lmm_fit_tau)
```

```{r}
library(sjPlot)
tab_model(lmm_fit_tau)
```